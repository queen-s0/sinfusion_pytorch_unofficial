{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62fb91fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "145d4c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'denoising-diffusion-pytorch/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3b6e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sinfusion.convnext import Block as ConvNextBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e267b78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a68e6b4",
   "metadata": {},
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af7bc184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Block                                    [1, 64, 32, 32]           64\n",
       "├─Conv2d: 1-1                            [1, 64, 32, 32]           3,200\n",
       "├─LayerNorm: 1-2                         [1, 32, 32, 64]           128\n",
       "├─Linear: 1-3                            [1, 32, 32, 256]          16,640\n",
       "├─GELU: 1-4                              [1, 32, 32, 256]          --\n",
       "├─Linear: 1-5                            [1, 32, 32, 64]           16,448\n",
       "├─Identity: 1-6                          [1, 64, 32, 32]           --\n",
       "==========================================================================================\n",
       "Total params: 36,480\n",
       "Trainable params: 36,480\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 3.31\n",
       "==========================================================================================\n",
       "Input size (MB): 0.26\n",
       "Forward/backward pass size (MB): 3.67\n",
       "Params size (MB): 0.15\n",
       "Estimated Total Size (MB): 4.08\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = ConvNextBlock(64)\n",
    "summary(block, input_size=(1, 64, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c395eac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.4300e-01,  6.7156e-01, -5.4269e-01,  ...,  4.2047e-01,\n",
       "            7.6600e-01,  1.0213e+00],\n",
       "          [ 5.9349e-01, -1.2021e+00, -2.3169e-01,  ...,  4.9485e-01,\n",
       "            7.1561e-01,  6.8871e-01],\n",
       "          [ 5.0260e-02, -1.0741e+00, -1.5700e+00,  ...,  1.3138e+00,\n",
       "            8.3342e-02,  5.7727e-01],\n",
       "          ...,\n",
       "          [-1.7141e+00, -1.7083e+00, -1.0414e+00,  ...,  9.0297e-02,\n",
       "           -1.0634e+00, -2.0310e-01],\n",
       "          [ 1.3243e+00, -8.9916e-01,  3.5622e-01,  ...,  2.3185e+00,\n",
       "            1.0020e+00,  9.6531e-01],\n",
       "          [-6.8497e-01,  1.0265e+00,  2.1010e-01,  ...,  4.8368e-01,\n",
       "           -9.2023e-02,  1.4771e-01]],\n",
       "\n",
       "         [[-1.1475e+00,  9.4339e-01, -5.0664e-02,  ..., -5.3286e-01,\n",
       "            1.0466e+00, -1.6284e+00],\n",
       "          [-5.2903e-02, -5.4705e-01,  1.3678e+00,  ...,  1.0006e+00,\n",
       "            1.3034e-01,  5.8654e-02],\n",
       "          [-1.3611e+00,  2.0250e-01, -2.8736e-01,  ...,  2.6533e-01,\n",
       "           -8.4345e-01,  4.5877e-01],\n",
       "          ...,\n",
       "          [-1.3834e+00,  3.3539e-01,  6.2209e-01,  ..., -1.3610e+00,\n",
       "            3.9845e-01,  1.0125e+00],\n",
       "          [ 6.2432e-01, -5.8012e-01, -1.5240e-01,  ...,  4.2137e-01,\n",
       "            2.0673e-01,  1.5353e+00],\n",
       "          [-1.2761e-03, -2.9395e-01, -1.4833e-01,  ...,  4.3314e-02,\n",
       "           -2.8451e-02,  7.1603e-01]],\n",
       "\n",
       "         [[-5.5287e-01,  2.9131e-01,  6.6096e-01,  ..., -1.3756e+00,\n",
       "            5.3386e-01,  7.5028e-01],\n",
       "          [-5.0631e-01, -1.1236e+00,  1.4492e+00,  ...,  1.8254e-01,\n",
       "           -4.5772e-01, -1.1732e+00],\n",
       "          [-1.0638e+00, -1.4498e-01,  7.9517e-02,  ..., -2.7582e+00,\n",
       "           -9.9264e-01, -1.6244e+00],\n",
       "          ...,\n",
       "          [-1.1664e-01,  5.6446e-01, -1.2706e+00,  ...,  1.6893e+00,\n",
       "           -1.0728e-01, -6.1447e-01],\n",
       "          [ 8.5189e-01, -3.3540e-02,  3.0738e-01,  ...,  6.0794e-01,\n",
       "            6.3545e-01,  1.9075e+00],\n",
       "          [-7.5417e-01, -1.4476e+00, -8.6851e-01,  ...,  1.5165e+00,\n",
       "           -8.1546e-01,  1.2561e+00]],\n",
       "\n",
       "         [[ 4.9910e-01,  4.9910e-01,  4.9910e-01,  ...,  4.9910e-01,\n",
       "            4.9910e-01,  4.9910e-01],\n",
       "          [ 4.9910e-01,  4.9910e-01,  4.9910e-01,  ...,  4.9910e-01,\n",
       "            4.9910e-01,  4.9910e-01],\n",
       "          [ 4.9910e-01,  4.9910e-01,  4.9910e-01,  ...,  4.9910e-01,\n",
       "            4.9910e-01,  4.9910e-01],\n",
       "          ...,\n",
       "          [ 4.9910e-01,  4.9910e-01,  4.9910e-01,  ...,  4.9910e-01,\n",
       "            4.9910e-01,  4.9910e-01],\n",
       "          [ 4.9910e-01,  4.9910e-01,  4.9910e-01,  ...,  4.9910e-01,\n",
       "            4.9910e-01,  4.9910e-01],\n",
       "          [ 4.9910e-01,  4.9910e-01,  4.9910e-01,  ...,  4.9910e-01,\n",
       "            4.9910e-01,  4.9910e-01]],\n",
       "\n",
       "         [[-1.2149e+00, -1.2149e+00, -1.2149e+00,  ..., -1.2149e+00,\n",
       "           -1.2149e+00, -1.2149e+00],\n",
       "          [-1.2149e+00, -1.2149e+00, -1.2149e+00,  ..., -1.2149e+00,\n",
       "           -1.2149e+00, -1.2149e+00],\n",
       "          [-1.2149e+00, -1.2149e+00, -1.2149e+00,  ..., -1.2149e+00,\n",
       "           -1.2149e+00, -1.2149e+00],\n",
       "          ...,\n",
       "          [-1.2149e+00, -1.2149e+00, -1.2149e+00,  ..., -1.2149e+00,\n",
       "           -1.2149e+00, -1.2149e+00],\n",
       "          [-1.2149e+00, -1.2149e+00, -1.2149e+00,  ..., -1.2149e+00,\n",
       "           -1.2149e+00, -1.2149e+00],\n",
       "          [-1.2149e+00, -1.2149e+00, -1.2149e+00,  ..., -1.2149e+00,\n",
       "           -1.2149e+00, -1.2149e+00]],\n",
       "\n",
       "         [[ 1.6211e+00,  1.6211e+00,  1.6211e+00,  ...,  1.6211e+00,\n",
       "            1.6211e+00,  1.6211e+00],\n",
       "          [ 1.6211e+00,  1.6211e+00,  1.6211e+00,  ...,  1.6211e+00,\n",
       "            1.6211e+00,  1.6211e+00],\n",
       "          [ 1.6211e+00,  1.6211e+00,  1.6211e+00,  ...,  1.6211e+00,\n",
       "            1.6211e+00,  1.6211e+00],\n",
       "          ...,\n",
       "          [ 1.6211e+00,  1.6211e+00,  1.6211e+00,  ...,  1.6211e+00,\n",
       "            1.6211e+00,  1.6211e+00],\n",
       "          [ 1.6211e+00,  1.6211e+00,  1.6211e+00,  ...,  1.6211e+00,\n",
       "            1.6211e+00,  1.6211e+00],\n",
       "          [ 1.6211e+00,  1.6211e+00,  1.6211e+00,  ...,  1.6211e+00,\n",
       "            1.6211e+00,  1.6211e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 1.8108e+00,  4.9786e-02,  2.8285e-02,  ..., -1.5333e+00,\n",
       "           -2.1008e+00, -1.1946e-01],\n",
       "          [ 5.6377e-01, -1.2319e+00, -2.0697e+00,  ...,  1.1154e+00,\n",
       "            4.1440e-01,  4.8050e-02],\n",
       "          [ 1.0307e-01, -4.8978e-01,  6.6125e-02,  ..., -5.0914e-01,\n",
       "            7.1347e-01,  9.0982e-01],\n",
       "          ...,\n",
       "          [-1.0439e+00,  6.1784e-01,  2.4230e-01,  ...,  1.6297e+00,\n",
       "           -9.3087e-01, -4.4146e-01],\n",
       "          [ 9.8660e-02,  8.8024e-01, -5.2511e-01,  ..., -1.6379e+00,\n",
       "            4.7861e-01, -3.4891e-01],\n",
       "          [-1.5352e-01, -8.2756e-01,  2.5266e+00,  ..., -5.3451e-01,\n",
       "            9.2773e-01, -5.7013e-01]],\n",
       "\n",
       "         [[ 2.2437e+00,  1.6466e+00, -2.3356e+00,  ..., -1.0752e+00,\n",
       "            1.1130e-01,  2.6350e-01],\n",
       "          [ 9.8278e-01, -2.9811e-01,  4.6939e-02,  ...,  9.5032e-01,\n",
       "            8.0414e-01, -6.7165e-01],\n",
       "          [ 1.7717e+00,  7.9393e-03, -1.1097e+00,  ...,  1.3822e-02,\n",
       "            3.6042e-01,  2.1885e-01],\n",
       "          ...,\n",
       "          [ 1.3481e+00, -9.8851e-01, -1.3415e+00,  ...,  2.8846e+00,\n",
       "           -6.8628e-01, -1.2347e+00],\n",
       "          [ 9.4983e-01,  4.1655e-02, -2.3109e-01,  ..., -1.0109e+00,\n",
       "            4.3300e-01,  1.1062e+00],\n",
       "          [ 1.7634e+00, -1.5378e-01,  1.4847e-01,  ...,  1.0506e+00,\n",
       "            9.1822e-01,  7.0326e-01]],\n",
       "\n",
       "         [[ 1.5979e+00, -5.4560e-01,  1.1789e-02,  ..., -3.5845e-01,\n",
       "           -2.0424e+00,  4.9279e-01],\n",
       "          [-5.1397e-01, -8.1325e-01, -1.2932e-01,  ...,  1.0010e+00,\n",
       "           -1.4079e+00, -5.8269e-02],\n",
       "          [-4.9427e-01,  1.2895e-01, -7.5581e-01,  ..., -4.9549e-01,\n",
       "            7.1618e-02,  8.4939e-03],\n",
       "          ...,\n",
       "          [-1.0698e+00, -1.4162e+00, -7.2074e-01,  ...,  1.0017e+00,\n",
       "           -8.8777e-01, -1.3372e+00],\n",
       "          [ 1.9749e+00,  1.0870e+00,  1.7967e+00,  ..., -6.4992e-01,\n",
       "            1.3362e+00,  3.0107e-01],\n",
       "          [ 4.2421e-01, -2.5054e+00, -3.7394e-01,  ..., -1.7747e+00,\n",
       "           -1.8380e+00, -2.8794e-01]],\n",
       "\n",
       "         [[ 4.9910e-01,  4.9910e-01,  4.9910e-01,  ...,  4.9910e-01,\n",
       "            4.9910e-01,  4.9910e-01],\n",
       "          [ 4.9910e-01,  4.9910e-01,  4.9910e-01,  ...,  4.9910e-01,\n",
       "            4.9910e-01,  4.9910e-01],\n",
       "          [ 4.9910e-01,  4.9910e-01,  4.9910e-01,  ...,  4.9910e-01,\n",
       "            4.9910e-01,  4.9910e-01],\n",
       "          ...,\n",
       "          [ 4.9910e-01,  4.9910e-01,  4.9910e-01,  ...,  4.9910e-01,\n",
       "            4.9910e-01,  4.9910e-01],\n",
       "          [ 4.9910e-01,  4.9910e-01,  4.9910e-01,  ...,  4.9910e-01,\n",
       "            4.9910e-01,  4.9910e-01],\n",
       "          [ 4.9910e-01,  4.9910e-01,  4.9910e-01,  ...,  4.9910e-01,\n",
       "            4.9910e-01,  4.9910e-01]],\n",
       "\n",
       "         [[-1.2149e+00, -1.2149e+00, -1.2149e+00,  ..., -1.2149e+00,\n",
       "           -1.2149e+00, -1.2149e+00],\n",
       "          [-1.2149e+00, -1.2149e+00, -1.2149e+00,  ..., -1.2149e+00,\n",
       "           -1.2149e+00, -1.2149e+00],\n",
       "          [-1.2149e+00, -1.2149e+00, -1.2149e+00,  ..., -1.2149e+00,\n",
       "           -1.2149e+00, -1.2149e+00],\n",
       "          ...,\n",
       "          [-1.2149e+00, -1.2149e+00, -1.2149e+00,  ..., -1.2149e+00,\n",
       "           -1.2149e+00, -1.2149e+00],\n",
       "          [-1.2149e+00, -1.2149e+00, -1.2149e+00,  ..., -1.2149e+00,\n",
       "           -1.2149e+00, -1.2149e+00],\n",
       "          [-1.2149e+00, -1.2149e+00, -1.2149e+00,  ..., -1.2149e+00,\n",
       "           -1.2149e+00, -1.2149e+00]],\n",
       "\n",
       "         [[ 1.6211e+00,  1.6211e+00,  1.6211e+00,  ...,  1.6211e+00,\n",
       "            1.6211e+00,  1.6211e+00],\n",
       "          [ 1.6211e+00,  1.6211e+00,  1.6211e+00,  ...,  1.6211e+00,\n",
       "            1.6211e+00,  1.6211e+00],\n",
       "          [ 1.6211e+00,  1.6211e+00,  1.6211e+00,  ...,  1.6211e+00,\n",
       "            1.6211e+00,  1.6211e+00],\n",
       "          ...,\n",
       "          [ 1.6211e+00,  1.6211e+00,  1.6211e+00,  ...,  1.6211e+00,\n",
       "            1.6211e+00,  1.6211e+00],\n",
       "          [ 1.6211e+00,  1.6211e+00,  1.6211e+00,  ...,  1.6211e+00,\n",
       "            1.6211e+00,  1.6211e+00],\n",
       "          [ 1.6211e+00,  1.6211e+00,  1.6211e+00,  ...,  1.6211e+00,\n",
       "            1.6211e+00,  1.6211e+00]]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 10, 10)\n",
    "repeats = list(x.shape)\n",
    "repeats[1] = 1\n",
    "y = torch.randn(3).view(1, -1, 1, 1).repeat(repeats)\n",
    "torch.cat([x, y], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62538835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from sinfusion.utils import default\n",
    "from einops import rearrange, reduce\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc88c288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1732, -0.3698,  0.6612,  ...,  0.6055, -0.3772, -0.0862],\n",
       "        [-0.9253, -0.8990, -0.6584,  ...,  0.2041, -0.5104, -0.8417],\n",
       "        [ 0.6976,  0.9990, -0.2290,  ..., -0.8438, -0.0327,  0.9238],\n",
       "        ...,\n",
       "        [ 0.6408,  0.9857, -0.4513,  ..., -0.9653,  0.5729,  0.9886],\n",
       "        [-0.7342, -0.9994,  0.0785,  ..., -0.7244, -0.4311,  0.7367],\n",
       "        [ 0.1889,  0.4016, -0.7090,  ...,  0.5369, -0.5351, -0.2346]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "class RandomOrLearnedSinusoidalPosEmb(nn.Module):\n",
    "    \"\"\" following @crowsonkb 's lead with random (learned optional) sinusoidal pos emb \"\"\"\n",
    "    \"\"\" https://github.com/crowsonkb/v-diffusion-jax/blob/master/diffusion/models/danbooru_128.py#L8 \"\"\"\n",
    "\n",
    "    def __init__(self, dim, is_random = False):\n",
    "        super().__init__()\n",
    "        assert (dim % 2) == 0\n",
    "        half_dim = dim // 2\n",
    "        self.weights = nn.Parameter(torch.randn(half_dim), requires_grad = not is_random)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = rearrange(x, 'b -> b 1')\n",
    "        freqs = x * rearrange(self.weights, 'd -> 1 d') * 2 * math.pi\n",
    "        fouriered = torch.cat((freqs.sin(), freqs.cos()), dim = -1)\n",
    "        fouriered = torch.cat((x, fouriered), dim = -1)\n",
    "        return fouriered\n",
    "    \n",
    "x = torch.randn(64)\n",
    "SinusoidalPosEmb(64)(x)\n",
    "RandomOrLearnedSinusoidalPosEmb(64)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71add6e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got multiple values for argument 'drop_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kh/k2c0gcw95yzbrb5k5p03_6k00000gn/T/ipykernel_15942/4140753845.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_mults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kh/k2c0gcw95yzbrb5k5p03_6k00000gn/T/ipykernel_15942/4140753845.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dim, init_dim, out_dim, dim_mults, channels, self_condition, learned_variance, learned_sinusoidal_cond, random_fourier_features, learned_sinusoidal_dim, drop_path, layer_scale_init_value)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# ]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             self.downs.append(nn.ModuleList([\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mblock_klass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_emb_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             ]))\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got multiple values for argument 'drop_path'"
     ]
    }
   ],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        init_dim = None,\n",
    "        out_dim = None,\n",
    "        dim_mults=(1, 2, 4, 8),\n",
    "        channels = 3,\n",
    "        self_condition = False,\n",
    "        # resnet_block_groups = 8,\n",
    "        learned_variance = False,\n",
    "        learned_sinusoidal_cond = False,\n",
    "        random_fourier_features = False,\n",
    "        learned_sinusoidal_dim = 16,\n",
    "        drop_path=0.0,\n",
    "        layer_scale_init_value=1e-6\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # determine dimensions\n",
    "\n",
    "        self.channels = channels\n",
    "        self.self_condition = self_condition\n",
    "        input_channels = channels * (2 if self_condition else 1)\n",
    "\n",
    "        init_dim = default(init_dim, dim)\n",
    "        self.init_conv = nn.Conv2d(input_channels, init_dim, 7, padding = 3)\n",
    "\n",
    "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "\n",
    "        # block_klass = partial(ResnetBlock, groups = resnet_block_groups)\n",
    "        block_klass = partial(ConvNextBlock, drop_path=drop_path, layer_scale_init_value=layer_scale_init_value)\n",
    "\n",
    "        # time embeddings\n",
    "\n",
    "        time_dim = dim * 4\n",
    "\n",
    "        self.random_or_learned_sinusoidal_cond = learned_sinusoidal_cond or random_fourier_features\n",
    "\n",
    "        if self.random_or_learned_sinusoidal_cond:\n",
    "            sinu_pos_emb = RandomOrLearnedSinusoidalPosEmb(learned_sinusoidal_dim, random_fourier_features)\n",
    "            fourier_dim = learned_sinusoidal_dim + 1\n",
    "        else:\n",
    "            sinu_pos_emb = SinusoidalPosEmb(dim)\n",
    "            fourier_dim = dim\n",
    "\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            sinu_pos_emb,\n",
    "            nn.Linear(fourier_dim, time_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(time_dim, time_dim)\n",
    "        )\n",
    "\n",
    "        # layers\n",
    "\n",
    "        self.downs = nn.ModuleList([])\n",
    "        self.ups = nn.ModuleList([])\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            # self.downs.append(nn.ModuleList([\n",
    "            #     block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n",
    "            #     block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n",
    "            #     Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
    "            #     Downsample(dim_in, dim_out) if not is_last else nn.Conv2d(dim_in, dim_out, 3, padding = 1)\n",
    "            # ]))\n",
    "            self.downs.append(nn.ModuleList([\n",
    "                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n",
    "            ]))\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
    "        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n",
    "        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out)):\n",
    "            is_last = ind == (len(in_out) - 1)\n",
    "\n",
    "            # self.ups.append(nn.ModuleList([\n",
    "            #     block_klass(dim_out + dim_in, dim_out, time_emb_dim = time_dim),\n",
    "            #     block_klass(dim_out + dim_in, dim_out, time_emb_dim = time_dim),\n",
    "            #     Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
    "            #     Upsample(dim_out, dim_in) if not is_last else  nn.Conv2d(dim_out, dim_in, 3, padding = 1)\n",
    "            # ]))\n",
    "\n",
    "        default_out_dim = channels * (1 if not learned_variance else 2)\n",
    "        self.out_dim = default(out_dim, default_out_dim)\n",
    "\n",
    "        self.final_res_block = block_klass(dim * 2, dim, time_emb_dim = time_dim)\n",
    "        self.final_conv = nn.Conv2d(dim, self.out_dim, 1)\n",
    "\n",
    "    def forward(self, x, time, x_self_cond = None):\n",
    "        if self.self_condition:\n",
    "            x_self_cond = default(x_self_cond, lambda: torch.zeros_like(x))\n",
    "            x = torch.cat((x_self_cond, x), dim = 1)\n",
    "\n",
    "        x = self.init_conv(x)\n",
    "        r = x.clone()\n",
    "\n",
    "        t = self.time_mlp(time)\n",
    "\n",
    "        h = []\n",
    "\n",
    "        for block1, block2 in self.downs:\n",
    "            x = block1(x, t)\n",
    "            h.append(x)\n",
    "\n",
    "            x = block2(x, t)\n",
    "            h.append(x)\n",
    "\n",
    "        x = self.mid_block1(x, t)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x, t)\n",
    "\n",
    "        for block1, block2 in self.ups:\n",
    "            x = torch.cat((x, h.pop()), dim = 1)\n",
    "            x = block1(x, t)\n",
    "\n",
    "            x = torch.cat((x, h.pop()), dim = 1)\n",
    "            x = block2(x, t)\n",
    "\n",
    "        x = torch.cat((x, r), dim = 1)\n",
    "\n",
    "        x = self.final_res_block(x, t)\n",
    "        return self.final_conv(x)\n",
    "\n",
    "    \n",
    "net = Unet(64, dim_mults=(1, 2, 4, 8))\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e5f8a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from denoising_diffusion_pytorch.denoising_diffusion_pytorch import Unet\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "net = Unet(64)\n",
    "summary(net, input_size=(1, 3, 32, 32), time=torch.randn(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb90e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
